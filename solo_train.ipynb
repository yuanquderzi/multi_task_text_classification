{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "2370c54a-c3f5-4493-986d-1a4d6b0bf67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "109c48ee-9c35-4831-83f1-d5fb40789a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the datasets\n",
    "df = pd.read_excel(\"./train.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "11482806-32a6-4d39-b38a-69ac43a8ed06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>BACE_Blank</th>\n",
       "      <th>DIS_Blank</th>\n",
       "      <th>IGB_Blank</th>\n",
       "      <th>SC_Blank</th>\n",
       "      <th>TASK_Blank</th>\n",
       "      <th>PWR_Blank</th>\n",
       "      <th>CC_Blank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-安东尼·布林肯/2010年9月7日布林肯关于美伊关系的演讲.txt</td>\n",
       "      <td>Celeste gentlemen let me welcome you to as the...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01-安东尼·布林肯/2014年4月7日布林肯在哥伦比亚大学进行关于人道主义行动的演讲.txt</td>\n",
       "      <td>So let me just make a very quick her welcome t...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-安东尼·布林肯/2015布林肯接受印度快报采访.txt</td>\n",
       "      <td>I'm going to be speaking today to antony bilki...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01-安东尼·布林肯/2016年4月布林肯特别演讲.txt</td>\n",
       "      <td>So I I have a special opportunity to uh huh mi...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01-安东尼·布林肯/2016年6月30日布林肯发表关于加入CSIS的演讲.txt</td>\n",
       "      <td>Could more.Everyone welcome to the center for ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              name  \\\n",
       "0             01-安东尼·布林肯/2010年9月7日布林肯关于美伊关系的演讲.txt   \n",
       "1  01-安东尼·布林肯/2014年4月7日布林肯在哥伦比亚大学进行关于人道主义行动的演讲.txt   \n",
       "2                   01-安东尼·布林肯/2015布林肯接受印度快报采访.txt   \n",
       "3                    01-安东尼·布林肯/2016年4月布林肯特别演讲.txt   \n",
       "4        01-安东尼·布林肯/2016年6月30日布林肯发表关于加入CSIS的演讲.txt   \n",
       "\n",
       "                                                text  BACE_Blank  DIS_Blank  \\\n",
       "0  Celeste gentlemen let me welcome you to as the...           1          2   \n",
       "1  So let me just make a very quick her welcome t...           2          4   \n",
       "2  I'm going to be speaking today to antony bilki...           1          3   \n",
       "3  So I I have a special opportunity to uh huh mi...           1          2   \n",
       "4  Could more.Everyone welcome to the center for ...           1          2   \n",
       "\n",
       "   IGB_Blank  SC_Blank  TASK_Blank  PWR_Blank  CC_Blank  \n",
       "0          1         4           4          1         3  \n",
       "1          1         2           3          2         4  \n",
       "2          1         4           3          1         4  \n",
       "3          1         3           3          1         2  \n",
       "4          1         4           1          1         3  "
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "c1db280a-8427-45c8-9fe9-a9a4f06901aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name          0\n",
       "text          0\n",
       "BACE_Blank    0\n",
       "DIS_Blank     0\n",
       "IGB_Blank     0\n",
       "SC_Blank      0\n",
       "TASK_Blank    0\n",
       "PWR_Blank     0\n",
       "CC_Blank      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "6ecc23c2-0f55-4d3a-964b-ecfacf367554",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dataway/anaconda3/envs/pytorch_env/lib/python3.8/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# tokenize the text using BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "820b0d6e-a190-439e-8c62-919ea5dbe706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define helper function for tokenization\n",
    "def tokenize_text(text):\n",
    "    return tokenizer.encode(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=256,\n",
    "        padding='max_length',\n",
    "        return_token_type_ids=True,\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "abbb149e-431a-406b-9799-51b7c3bdec73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 48.94it/s]\n"
     ]
    }
   ],
   "source": [
    "# tokenize texts in corpus using BERT tokenizer\n",
    "# 模型的输入将是标记化的文本标记和注意力掩码。\n",
    "df['input_ids'] = [tokenize_text(text) for text in tqdm(df['text'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "aa3a1224-dc88-4c9b-a9c3-fea4f6956ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>BACE_Blank</th>\n",
       "      <th>DIS_Blank</th>\n",
       "      <th>IGB_Blank</th>\n",
       "      <th>SC_Blank</th>\n",
       "      <th>TASK_Blank</th>\n",
       "      <th>PWR_Blank</th>\n",
       "      <th>CC_Blank</th>\n",
       "      <th>input_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>07-麻生太郎/3.txt</td>\n",
       "      <td>first Taro Aso. I decided to dissolve the hous...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[[tensor(101), tensor(2034), tensor(16985), te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>15-约瑟夫·拜登/拜登2020感恩节讲稿.txt</td>\n",
       "      <td>My fellow Americans:Thanksgiving is a special ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[[tensor(101), tensor(2026), tensor(3507), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>03-福田康夫/5.txt</td>\n",
       "      <td>It is said that it is 14 times in this year th...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[[tensor(101), tensor(2009), tensor(2003), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>01-安倍晋三/6.txt</td>\n",
       "      <td>Good morning to you all. When President Juncke...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[[tensor(101), tensor(2204), tensor(2851), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>01-安倍晋三/10.txt</td>\n",
       "      <td>Welcome to Yokohama. My thanks go to President...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>[[tensor(101), tensor(6160), tensor(2000), ten...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          name  \\\n",
       "92               07-麻生太郎/3.txt   \n",
       "152  15-约瑟夫·拜登/拜登2020感恩节讲稿.txt   \n",
       "35               03-福田康夫/5.txt   \n",
       "23               01-安倍晋三/6.txt   \n",
       "10              01-安倍晋三/10.txt   \n",
       "\n",
       "                                                  text  BACE_Blank  DIS_Blank  \\\n",
       "92   first Taro Aso. I decided to dissolve the hous...           3          1   \n",
       "152  My fellow Americans:Thanksgiving is a special ...           2          2   \n",
       "35   It is said that it is 14 times in this year th...           1          1   \n",
       "23   Good morning to you all. When President Juncke...           4          1   \n",
       "10   Welcome to Yokohama. My thanks go to President...           4          1   \n",
       "\n",
       "     IGB_Blank  SC_Blank  TASK_Blank  PWR_Blank  CC_Blank  \\\n",
       "92           1         2           4          1         4   \n",
       "152          1         1           1          2         1   \n",
       "35           1         4           3          1         4   \n",
       "23           1         1           2          4         1   \n",
       "10           1         1           3          4         3   \n",
       "\n",
       "                                             input_ids  \n",
       "92   [[tensor(101), tensor(2034), tensor(16985), te...  \n",
       "152  [[tensor(101), tensor(2026), tensor(3507), ten...  \n",
       "35   [[tensor(101), tensor(2009), tensor(2003), ten...  \n",
       "23   [[tensor(101), tensor(2204), tensor(2851), ten...  \n",
       "10   [[tensor(101), tensor(6160), tensor(2000), ten...  "
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform train validation split\n",
    "df_train, df_val = train_test_split(df, test_size=0.2, random_state=2024)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "e80960a5-0a03-460a-8b01-594c1606fe5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CC_Blank\n",
       "4    40\n",
       "3    30\n",
       "2    28\n",
       "1    27\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['CC_Blank'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "7e2b6850-0979-49d6-ab48-19a6e68d3c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CC_Blank\n",
       "1    12\n",
       "2     8\n",
       "4     6\n",
       "3     6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val['CC_Blank'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "c6162862-266e-4a16-850b-5327b4e609ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2034, 16985,  ...,  2001,  2019,   102],\n",
       "        [  101,  2026,  3507,  ...,  1011,  2146,   102],\n",
       "        [  101,  2009,  2003,  ...,  1045,  2052,   102],\n",
       "        ...,\n",
       "        [  101,  2651,  1010,  ...,  1996,  2601,   102],\n",
       "        [  101, 15876,  9743,  ...,  2001,  2055,   102],\n",
       "        [  101,  2206,  1996,  ...,  7803, 17371,   102]])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get tokens from train and validation sets\n",
    "df_train_tokens = torch.from_numpy(np.vstack(df_train['input_ids']))\n",
    "df_val_tokens = torch.from_numpy(np.vstack(df_val['input_ids']))\n",
    "df_train_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "dd3bd384-8b39-45c1-b338-ff3ddcc836c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1]])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get attention masks from train and validation sets\n",
    "df_train_attention_masks = torch.where(df_train_tokens!=0, 1, 0)\n",
    "df_val_attention_masks = torch.where(df_val_tokens!=0, 1, 0)\n",
    "df_train_attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "faf52559-29e9-49c1-afc9-21eb47482899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>BACE_Blank</th>\n",
       "      <th>DIS_Blank</th>\n",
       "      <th>IGB_Blank</th>\n",
       "      <th>SC_Blank</th>\n",
       "      <th>TASK_Blank</th>\n",
       "      <th>PWR_Blank</th>\n",
       "      <th>CC_Blank</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_masks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>07-麻生太郎/3.txt</td>\n",
       "      <td>first Taro Aso. I decided to dissolve the hous...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[[tensor(101), tensor(2034), tensor(16985), te...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>15-约瑟夫·拜登/拜登2020感恩节讲稿.txt</td>\n",
       "      <td>My fellow Americans:Thanksgiving is a special ...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[[tensor(101), tensor(2026), tensor(3507), ten...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>03-福田康夫/5.txt</td>\n",
       "      <td>It is said that it is 14 times in this year th...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[[tensor(101), tensor(2009), tensor(2003), ten...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>01-安倍晋三/6.txt</td>\n",
       "      <td>Good morning to you all. When President Juncke...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[[tensor(101), tensor(2204), tensor(2851), ten...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>01-安倍晋三/10.txt</td>\n",
       "      <td>Welcome to Yokohama. My thanks go to President...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>[[tensor(101), tensor(6160), tensor(2000), ten...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          name  \\\n",
       "92               07-麻生太郎/3.txt   \n",
       "152  15-约瑟夫·拜登/拜登2020感恩节讲稿.txt   \n",
       "35               03-福田康夫/5.txt   \n",
       "23               01-安倍晋三/6.txt   \n",
       "10              01-安倍晋三/10.txt   \n",
       "\n",
       "                                                  text  BACE_Blank  DIS_Blank  \\\n",
       "92   first Taro Aso. I decided to dissolve the hous...           3          1   \n",
       "152  My fellow Americans:Thanksgiving is a special ...           2          2   \n",
       "35   It is said that it is 14 times in this year th...           1          1   \n",
       "23   Good morning to you all. When President Juncke...           4          1   \n",
       "10   Welcome to Yokohama. My thanks go to President...           4          1   \n",
       "\n",
       "     IGB_Blank  SC_Blank  TASK_Blank  PWR_Blank  CC_Blank  \\\n",
       "92           1         2           4          1         4   \n",
       "152          1         1           1          2         1   \n",
       "35           1         4           3          1         4   \n",
       "23           1         1           2          4         1   \n",
       "10           1         1           3          4         3   \n",
       "\n",
       "                                             input_ids  \\\n",
       "92   [[tensor(101), tensor(2034), tensor(16985), te...   \n",
       "152  [[tensor(101), tensor(2026), tensor(3507), ten...   \n",
       "35   [[tensor(101), tensor(2009), tensor(2003), ten...   \n",
       "23   [[tensor(101), tensor(2204), tensor(2851), ten...   \n",
       "10   [[tensor(101), tensor(6160), tensor(2000), ten...   \n",
       "\n",
       "                                       attention_masks  \n",
       "92   [tensor(1), tensor(1), tensor(1), tensor(1), t...  \n",
       "152  [tensor(1), tensor(1), tensor(1), tensor(1), t...  \n",
       "35   [tensor(1), tensor(1), tensor(1), tensor(1), t...  \n",
       "23   [tensor(1), tensor(1), tensor(1), tensor(1), t...  \n",
       "10   [tensor(1), tensor(1), tensor(1), tensor(1), t...  "
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['attention_masks'] = [i for i in df_train_attention_masks]\n",
    "df_val['attention_masks'] = [i for i in df_val_attention_masks]\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "8a952ec7-2864-4e8b-90c1-fed6598f0a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "29f0d035-d69b-461c-bd24-0b113680ff13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "6b08c374-515f-4c5c-8211-85a5d166f5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the neural network model\n",
    "class DisasterSentimentModel(nn.Module):\n",
    "    def __init__(self, num_labels1):\n",
    "        super(DisasterSentimentModel, self).__init__()\n",
    "        self.bert_layer = BertModel.from_pretrained('bert-base-uncased')\n",
    "        for param in self.bert_layer.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.dropout_layer = nn.Dropout(0.3)\n",
    "        \n",
    "        self.dense_layer1 = nn.Linear(self.bert_layer.config.hidden_size, 512)\n",
    "        self.classifier_layer1 = nn.Linear(512, num_labels1)\n",
    "        \n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        bert_output = self.bert_layer(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = bert_output[0]\n",
    "        pooled_output = pooled_output[:, 0]\n",
    "        \n",
    "        output1 = self.dense_layer1(pooled_output)\n",
    "        output1 = nn.ReLU()(output1)\n",
    "        output1 = self.dropout_layer(output1)\n",
    "        output1 = torch.softmax(self.classifier_layer1(output1), dim=-1)\n",
    "\n",
    "        #return output1, output2, output3, output4, output5, output6, output7\n",
    "        return output1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "cf1cde03-eda3-4b2d-8184-be18f59965d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loader for Multi-Task Learning\n",
    "batch_size = 16\n",
    "\n",
    "input_ids = torch.from_numpy(np.vstack(df_train['input_ids'].values))\n",
    "attention_masks = torch.from_numpy(np.vstack(df_train['attention_masks'].values))\n",
    "d1_label = torch.from_numpy(np.vstack(df_train['CC_Blank'].values))\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(input_ids,\n",
    "                                                attention_masks,\n",
    "                                                d1_label,\n",
    "                                                )\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "8bafd8f0-544c-48ee-85cc-da3c7f699d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_task_train(model, dataloader, max_epochs, print_loss=False):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            input_ids, attention_masks, d1_label = batch\n",
    "\n",
    "            # 将标签从二维转为一维，并进行 0-based 映射\n",
    "            d1_label = d1_label.view(-1).long() - 1\n",
    "\n",
    "            # 前向传播\n",
    "            outputs = model(input_ids, attention_masks)\n",
    "\n",
    "            # 调试输出\n",
    "            print(f\"Model output shape: {outputs.shape}, Target shape: {d1_label.shape}\")\n",
    "\n",
    "            # 计算损失\n",
    "            loss = loss_fn(outputs, d1_label)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            if print_loss:\n",
    "                print(f\"Batch {batch_idx + 1}/{len(dataloader)}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{max_epochs}, Average Loss: {total_loss / len(dataloader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "1d5ef533-5010-45e8-9b4f-7077a8944258",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dataway/anaconda3/envs/pytorch_env/lib/python3.8/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 1/8, Loss: 1.3912\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 2/8, Loss: 1.3893\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 3/8, Loss: 1.3941\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 4/8, Loss: 1.3939\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 5/8, Loss: 1.3734\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 6/8, Loss: 1.3828\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 7/8, Loss: 1.3887\n",
      "Model output shape: torch.Size([13, 4]), Target shape: torch.Size([13])\n",
      "Batch 8/8, Loss: 1.3770\n",
      "Epoch 1/10, Average Loss: 1.3863\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 1/8, Loss: 1.3659\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 2/8, Loss: 1.3562\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 3/8, Loss: 1.3791\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 4/8, Loss: 1.3950\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 5/8, Loss: 1.3850\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 6/8, Loss: 1.3703\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 7/8, Loss: 1.3619\n",
      "Model output shape: torch.Size([13, 4]), Target shape: torch.Size([13])\n",
      "Batch 8/8, Loss: 1.3536\n",
      "Epoch 2/10, Average Loss: 1.3709\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 1/8, Loss: 1.3610\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 2/8, Loss: 1.3754\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 3/8, Loss: 1.3485\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 4/8, Loss: 1.3719\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 5/8, Loss: 1.3467\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 6/8, Loss: 1.3625\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 7/8, Loss: 1.3529\n",
      "Model output shape: torch.Size([13, 4]), Target shape: torch.Size([13])\n",
      "Batch 8/8, Loss: 1.3672\n",
      "Epoch 3/10, Average Loss: 1.3608\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 1/8, Loss: 1.4141\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 2/8, Loss: 1.3242\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 3/8, Loss: 1.3314\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 4/8, Loss: 1.3802\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 5/8, Loss: 1.3375\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 6/8, Loss: 1.3605\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 7/8, Loss: 1.3056\n",
      "Model output shape: torch.Size([13, 4]), Target shape: torch.Size([13])\n",
      "Batch 8/8, Loss: 1.3891\n",
      "Epoch 4/10, Average Loss: 1.3553\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 1/8, Loss: 1.2874\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 2/8, Loss: 1.3893\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 3/8, Loss: 1.3566\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 4/8, Loss: 1.3843\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 5/8, Loss: 1.3623\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 6/8, Loss: 1.3261\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 7/8, Loss: 1.3323\n",
      "Model output shape: torch.Size([13, 4]), Target shape: torch.Size([13])\n",
      "Batch 8/8, Loss: 1.3305\n",
      "Epoch 5/10, Average Loss: 1.3461\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 1/8, Loss: 1.3693\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 2/8, Loss: 1.3753\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 3/8, Loss: 1.3208\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 4/8, Loss: 1.3431\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 5/8, Loss: 1.3132\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 6/8, Loss: 1.3314\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 7/8, Loss: 1.3510\n",
      "Model output shape: torch.Size([13, 4]), Target shape: torch.Size([13])\n",
      "Batch 8/8, Loss: 1.3191\n",
      "Epoch 6/10, Average Loss: 1.3404\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 1/8, Loss: 1.3294\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 2/8, Loss: 1.2962\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 3/8, Loss: 1.3720\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 4/8, Loss: 1.3587\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 5/8, Loss: 1.3281\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 6/8, Loss: 1.2713\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 7/8, Loss: 1.3856\n",
      "Model output shape: torch.Size([13, 4]), Target shape: torch.Size([13])\n",
      "Batch 8/8, Loss: 1.3622\n",
      "Epoch 7/10, Average Loss: 1.3379\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 1/8, Loss: 1.3104\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 2/8, Loss: 1.3088\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 3/8, Loss: 1.3332\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 4/8, Loss: 1.4153\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 5/8, Loss: 1.3203\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 6/8, Loss: 1.3053\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 7/8, Loss: 1.3837\n",
      "Model output shape: torch.Size([13, 4]), Target shape: torch.Size([13])\n",
      "Batch 8/8, Loss: 1.2307\n",
      "Epoch 8/10, Average Loss: 1.3259\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 1/8, Loss: 1.2706\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 2/8, Loss: 1.3753\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 3/8, Loss: 1.3661\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 4/8, Loss: 1.2925\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 5/8, Loss: 1.3059\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 6/8, Loss: 1.3303\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 7/8, Loss: 1.3392\n",
      "Model output shape: torch.Size([13, 4]), Target shape: torch.Size([13])\n",
      "Batch 8/8, Loss: 1.3216\n",
      "Epoch 9/10, Average Loss: 1.3252\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 1/8, Loss: 1.2839\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 2/8, Loss: 1.3276\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 3/8, Loss: 1.3389\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 4/8, Loss: 1.2624\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 5/8, Loss: 1.3150\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 6/8, Loss: 1.3483\n",
      "Model output shape: torch.Size([16, 4]), Target shape: torch.Size([16])\n",
      "Batch 7/8, Loss: 1.3550\n",
      "Model output shape: torch.Size([13, 4]), Target shape: torch.Size([13])\n",
      "Batch 8/8, Loss: 1.3101\n",
      "Epoch 10/10, Average Loss: 1.3176\n"
     ]
    }
   ],
   "source": [
    "# define new model to train on both d1 and d2 labels\n",
    "md = DisasterSentimentModel(num_labels1=4).to(device)\n",
    "single_task_train(md, train_loader, 10, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "963b07d5-9c80-4792-b041-07adea45b0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "def evaluate(model, dataloader, return_labels=False):\n",
    "    \"\"\"\n",
    "    评估模型性能，计算 F1 分数和准确率。\n",
    "    \n",
    "    参数:\n",
    "        model: 要评估的模型。\n",
    "        dataloader: 数据加载器。\n",
    "        return_labels: 如果为 True，则返回预测标签和实际标签。\n",
    "        \n",
    "    返回:\n",
    "        f1: F1 分数。\n",
    "        accuracy: 准确率。\n",
    "        如果 return_labels 为 True，则返回 (f1, accuracy, predictions, true_labels)。\n",
    "    \"\"\"\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    all_predictions = []\n",
    "    all_true_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            input_ids, attention_masks, d1_label = batch\n",
    "\n",
    "            # 将标签从二维转为一维，并进行 0-based 映射\n",
    "            d1_label = d1_label.view(-1).long() - 1\n",
    "\n",
    "            # 模型输出\n",
    "            outputs = model(input_ids, attention_masks)\n",
    "\n",
    "            # 获取预测类别\n",
    "            predictions = torch.argmax(outputs, dim=1)\n",
    "\n",
    "            # 收集预测和真实标签\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_true_labels.extend(d1_label.cpu().numpy())\n",
    "\n",
    "    # 计算 F1 分数和准确率\n",
    "    f1 = f1_score(all_true_labels, all_predictions, average='weighted')\n",
    "    accuracy = accuracy_score(all_true_labels, all_predictions)\n",
    "    print(f\"F1 Score: {f1:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    if return_labels:\n",
    "        return f1, accuracy, all_predictions, all_true_labels\n",
    "    return f1, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "1bab1454-fb60-4d95-956e-31d37a7b0213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loader for Multi-Task Learning\n",
    "batch_size = 16\n",
    "\n",
    "input_ids = torch.from_numpy(np.vstack(df_val['input_ids'].values))\n",
    "attention_masks = torch.from_numpy(np.vstack(df_val['attention_masks'].values))\n",
    "d1_label = torch.from_numpy(np.vstack(df_val['CC_Blank'].values))\n",
    "\n",
    "val_data = torch.utils.data.TensorDataset(input_ids,\n",
    "                                                attention_masks,\n",
    "                                                d1_label)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "8d2ab8af-44e9-405c-82b8-fe87208a1f24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.2809, Accuracy: 0.3438\n"
     ]
    }
   ],
   "source": [
    "f1, accuracy, all_predictions, all_true_labels = evaluate(md, val_loader, return_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f3d017-48fa-48ee-a9b5-ca4c3a71d46d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118010e9-d32c-4952-951d-2cf4b0497c14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
