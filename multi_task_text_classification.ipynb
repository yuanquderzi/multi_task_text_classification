{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3384f922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041a8f8d-b8ba-4407-b92a-c7f392eeb9ae",
   "metadata": {},
   "source": [
    "1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ec9f2f7-1dab-47b0-9515-af764452b5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the datasets\n",
    "df = pd.read_excel(\"./train.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "943bd5bf-4415-49b8-97a9-ace4554bc79b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>BACE_Blank</th>\n",
       "      <th>DIS_Blank</th>\n",
       "      <th>IGB_Blank</th>\n",
       "      <th>SC_Blank</th>\n",
       "      <th>TASK_Blank</th>\n",
       "      <th>PWR_Blank</th>\n",
       "      <th>CC_Blank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-安东尼·布林肯/2010年9月7日布林肯关于美伊关系的演讲.txt</td>\n",
       "      <td>Celeste gentlemen let me welcome you to as the...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01-安东尼·布林肯/2014年4月7日布林肯在哥伦比亚大学进行关于人道主义行动的演讲.txt</td>\n",
       "      <td>So let me just make a very quick her welcome t...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-安东尼·布林肯/2015布林肯接受印度快报采访.txt</td>\n",
       "      <td>I'm going to be speaking today to antony bilki...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01-安东尼·布林肯/2016年4月布林肯特别演讲.txt</td>\n",
       "      <td>So I I have a special opportunity to uh huh mi...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01-安东尼·布林肯/2016年6月30日布林肯发表关于加入CSIS的演讲.txt</td>\n",
       "      <td>Could more.Everyone welcome to the center for ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              name  \\\n",
       "0             01-安东尼·布林肯/2010年9月7日布林肯关于美伊关系的演讲.txt   \n",
       "1  01-安东尼·布林肯/2014年4月7日布林肯在哥伦比亚大学进行关于人道主义行动的演讲.txt   \n",
       "2                   01-安东尼·布林肯/2015布林肯接受印度快报采访.txt   \n",
       "3                    01-安东尼·布林肯/2016年4月布林肯特别演讲.txt   \n",
       "4        01-安东尼·布林肯/2016年6月30日布林肯发表关于加入CSIS的演讲.txt   \n",
       "\n",
       "                                                text  BACE_Blank  DIS_Blank  \\\n",
       "0  Celeste gentlemen let me welcome you to as the...           1          2   \n",
       "1  So let me just make a very quick her welcome t...           2          4   \n",
       "2  I'm going to be speaking today to antony bilki...           1          3   \n",
       "3  So I I have a special opportunity to uh huh mi...           1          2   \n",
       "4  Could more.Everyone welcome to the center for ...           1          2   \n",
       "\n",
       "   IGB_Blank  SC_Blank  TASK_Blank  PWR_Blank  CC_Blank  \n",
       "0          1         4           4          1         3  \n",
       "1          1         2           3          2         4  \n",
       "2          1         4           3          1         4  \n",
       "3          1         3           3          1         2  \n",
       "4          1         4           1          1         3  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50fe117-4f6e-4d6c-87a9-d3d3aeef2ac9",
   "metadata": {},
   "source": [
    "2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4beec2e7-b163-4f7f-9167-0e7bcdd0fafb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name          0\n",
       "text          0\n",
       "BACE_Blank    0\n",
       "DIS_Blank     0\n",
       "IGB_Blank     0\n",
       "SC_Blank      0\n",
       "TASK_Blank    0\n",
       "PWR_Blank     0\n",
       "CC_Blank      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31351ede-964d-4350-a245-3a84446d2c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dataway/anaconda3/envs/pytorch_env/lib/python3.8/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# tokenize the text using BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "49f6ae28-366e-4270-a75c-c4755cd607db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define helper function for tokenization\n",
    "def tokenize_text(text):\n",
    "    return tokenizer.encode(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=256,\n",
    "        padding='max_length',\n",
    "        return_token_type_ids=True,\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "74a68846-4e6a-4f54-9b24-caa40e205090",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:03<00:00, 47.14it/s]\n"
     ]
    }
   ],
   "source": [
    "# tokenize texts in corpus using BERT tokenizer\n",
    "# 模型的输入将是标记化的文本标记和注意力掩码。\n",
    "df['input_ids'] = [tokenize_text(text) for text in tqdm(df['text'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e63de544-8150-40f6-bf7e-c5a0ba3fa40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>BACE_Blank</th>\n",
       "      <th>DIS_Blank</th>\n",
       "      <th>IGB_Blank</th>\n",
       "      <th>SC_Blank</th>\n",
       "      <th>TASK_Blank</th>\n",
       "      <th>PWR_Blank</th>\n",
       "      <th>CC_Blank</th>\n",
       "      <th>input_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-安东尼·布林肯/2010年9月7日布林肯关于美伊关系的演讲.txt</td>\n",
       "      <td>Celeste gentlemen let me welcome you to as the...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[[tensor(101), tensor(21113), tensor(11218), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01-安东尼·布林肯/2014年4月7日布林肯在哥伦比亚大学进行关于人道主义行动的演讲.txt</td>\n",
       "      <td>So let me just make a very quick her welcome t...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>[[tensor(101), tensor(2061), tensor(2292), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-安东尼·布林肯/2015布林肯接受印度快报采访.txt</td>\n",
       "      <td>I'm going to be speaking today to antony bilki...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>[[tensor(101), tensor(1045), tensor(1005), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01-安东尼·布林肯/2016年4月布林肯特别演讲.txt</td>\n",
       "      <td>So I I have a special opportunity to uh huh mi...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[[tensor(101), tensor(2061), tensor(1045), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01-安东尼·布林肯/2016年6月30日布林肯发表关于加入CSIS的演讲.txt</td>\n",
       "      <td>Could more.Everyone welcome to the center for ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[[tensor(101), tensor(2071), tensor(2062), ten...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              name  \\\n",
       "0             01-安东尼·布林肯/2010年9月7日布林肯关于美伊关系的演讲.txt   \n",
       "1  01-安东尼·布林肯/2014年4月7日布林肯在哥伦比亚大学进行关于人道主义行动的演讲.txt   \n",
       "2                   01-安东尼·布林肯/2015布林肯接受印度快报采访.txt   \n",
       "3                    01-安东尼·布林肯/2016年4月布林肯特别演讲.txt   \n",
       "4        01-安东尼·布林肯/2016年6月30日布林肯发表关于加入CSIS的演讲.txt   \n",
       "\n",
       "                                                text  BACE_Blank  DIS_Blank  \\\n",
       "0  Celeste gentlemen let me welcome you to as the...           1          2   \n",
       "1  So let me just make a very quick her welcome t...           2          4   \n",
       "2  I'm going to be speaking today to antony bilki...           1          3   \n",
       "3  So I I have a special opportunity to uh huh mi...           1          2   \n",
       "4  Could more.Everyone welcome to the center for ...           1          2   \n",
       "\n",
       "   IGB_Blank  SC_Blank  TASK_Blank  PWR_Blank  CC_Blank  \\\n",
       "0          1         4           4          1         3   \n",
       "1          1         2           3          2         4   \n",
       "2          1         4           3          1         4   \n",
       "3          1         3           3          1         2   \n",
       "4          1         4           1          1         3   \n",
       "\n",
       "                                           input_ids  \n",
       "0  [[tensor(101), tensor(21113), tensor(11218), t...  \n",
       "1  [[tensor(101), tensor(2061), tensor(2292), ten...  \n",
       "2  [[tensor(101), tensor(1045), tensor(1005), ten...  \n",
       "3  [[tensor(101), tensor(2061), tensor(1045), ten...  \n",
       "4  [[tensor(101), tensor(2071), tensor(2062), ten...  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d582c5f7-b87d-46fe-bde7-2e25435c115d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>BACE_Blank</th>\n",
       "      <th>DIS_Blank</th>\n",
       "      <th>IGB_Blank</th>\n",
       "      <th>SC_Blank</th>\n",
       "      <th>TASK_Blank</th>\n",
       "      <th>PWR_Blank</th>\n",
       "      <th>CC_Blank</th>\n",
       "      <th>input_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>01-安倍晋三/6.txt</td>\n",
       "      <td>Good morning to you all. When President Juncke...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[[tensor(101), tensor(2204), tensor(2851), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>01-安倍晋三/17.txt</td>\n",
       "      <td>Thank you very much for your introduction. Pri...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>[[tensor(101), tensor(4067), tensor(2017), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>01-安倍晋三/27.txt</td>\n",
       "      <td>Happy new year to everyone. I hope that you al...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[[tensor(101), tensor(3407), tensor(2047), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>05-菅直人/13.txt</td>\n",
       "      <td>We, the leaders of Japan, the People's Republi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[[tensor(101), tensor(2057), tensor(1010), ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>10-小渕恵三/9.txt</td>\n",
       "      <td>First, I will tell you about the accident of t...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>[[tensor(101), tensor(2034), tensor(1010), ten...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name                                               text  \\\n",
       "23    01-安倍晋三/6.txt  Good morning to you all. When President Juncke...   \n",
       "14   01-安倍晋三/17.txt  Thank you very much for your introduction. Pri...   \n",
       "21   01-安倍晋三/27.txt  Happy new year to everyone. I hope that you al...   \n",
       "57    05-菅直人/13.txt  We, the leaders of Japan, the People's Republi...   \n",
       "132   10-小渕恵三/9.txt  First, I will tell you about the accident of t...   \n",
       "\n",
       "     BACE_Blank  DIS_Blank  IGB_Blank  SC_Blank  TASK_Blank  PWR_Blank  \\\n",
       "23            4          1          1         1           2          4   \n",
       "14            4          1          1         1           1          4   \n",
       "21            4          1          1         1           1          4   \n",
       "57            1          1          1         4           2          1   \n",
       "132           3          1          1         2           2          4   \n",
       "\n",
       "     CC_Blank                                          input_ids  \n",
       "23          1  [[tensor(101), tensor(2204), tensor(2851), ten...  \n",
       "14          2  [[tensor(101), tensor(4067), tensor(2017), ten...  \n",
       "21          1  [[tensor(101), tensor(3407), tensor(2047), ten...  \n",
       "57          1  [[tensor(101), tensor(2057), tensor(1010), ten...  \n",
       "132         3  [[tensor(101), tensor(2034), tensor(1010), ten...  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform train validation split\n",
    "df_train, df_val = train_test_split(df, test_size=0.2, random_state=2023)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b0fee72c-c281-47fc-b113-283a7a1ee10e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DIS_Blank\n",
       "1    89\n",
       "4    16\n",
       "2    12\n",
       "3     8\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['DIS_Blank'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "67b052ae-24fa-4335-8031-401f46cd825f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DIS_Blank\n",
       "1    21\n",
       "2     7\n",
       "4     3\n",
       "3     1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val['DIS_Blank'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6d6d14f0-9eaa-409f-bc7f-4992adcde4c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101,  2204,  2851,  ...,  2900,  1998,   102],\n",
       "        [  101,  4067,  2017,  ...,  2005,  2129,   102],\n",
       "        [  101,  3407,  2047,  ..., 10575,  1998,   102],\n",
       "        ...,\n",
       "        [  101,  2061,  1045,  ...,  2057,  2134,   102],\n",
       "        [  101,  2343, 22072,  ...,  3713,  7580,   102],\n",
       "        [  101,  2057,  2018,  ...,  3314,  1010,   102]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get tokens from train and validation sets\n",
    "df_train_tokens = torch.from_numpy(np.vstack(df_train['input_ids']))\n",
    "df_val_tokens = torch.from_numpy(np.vstack(df_val['input_ids']))\n",
    "df_train_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "cff85f64-6412-41c5-8a54-7e88639d5e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 1, 1, 1]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get attention masks from train and validation sets\n",
    "df_train_attention_masks = torch.where(df_train_tokens!=0, 1, 0)\n",
    "df_val_attention_masks = torch.where(df_val_tokens!=0, 1, 0)\n",
    "df_train_attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "70768e96-383c-4402-81ca-723108236ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>text</th>\n",
       "      <th>BACE_Blank</th>\n",
       "      <th>DIS_Blank</th>\n",
       "      <th>IGB_Blank</th>\n",
       "      <th>SC_Blank</th>\n",
       "      <th>TASK_Blank</th>\n",
       "      <th>PWR_Blank</th>\n",
       "      <th>CC_Blank</th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_masks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>01-安倍晋三/6.txt</td>\n",
       "      <td>Good morning to you all. When President Juncke...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[[tensor(101), tensor(2204), tensor(2851), ten...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>01-安倍晋三/17.txt</td>\n",
       "      <td>Thank you very much for your introduction. Pri...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>[[tensor(101), tensor(4067), tensor(2017), ten...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>01-安倍晋三/27.txt</td>\n",
       "      <td>Happy new year to everyone. I hope that you al...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[[tensor(101), tensor(3407), tensor(2047), ten...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>05-菅直人/13.txt</td>\n",
       "      <td>We, the leaders of Japan, the People's Republi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[[tensor(101), tensor(2057), tensor(1010), ten...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>10-小渕恵三/9.txt</td>\n",
       "      <td>First, I will tell you about the accident of t...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>[[tensor(101), tensor(2034), tensor(1010), ten...</td>\n",
       "      <td>[tensor(1), tensor(1), tensor(1), tensor(1), t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name                                               text  \\\n",
       "23    01-安倍晋三/6.txt  Good morning to you all. When President Juncke...   \n",
       "14   01-安倍晋三/17.txt  Thank you very much for your introduction. Pri...   \n",
       "21   01-安倍晋三/27.txt  Happy new year to everyone. I hope that you al...   \n",
       "57    05-菅直人/13.txt  We, the leaders of Japan, the People's Republi...   \n",
       "132   10-小渕恵三/9.txt  First, I will tell you about the accident of t...   \n",
       "\n",
       "     BACE_Blank  DIS_Blank  IGB_Blank  SC_Blank  TASK_Blank  PWR_Blank  \\\n",
       "23            4          1          1         1           2          4   \n",
       "14            4          1          1         1           1          4   \n",
       "21            4          1          1         1           1          4   \n",
       "57            1          1          1         4           2          1   \n",
       "132           3          1          1         2           2          4   \n",
       "\n",
       "     CC_Blank                                          input_ids  \\\n",
       "23          1  [[tensor(101), tensor(2204), tensor(2851), ten...   \n",
       "14          2  [[tensor(101), tensor(4067), tensor(2017), ten...   \n",
       "21          1  [[tensor(101), tensor(3407), tensor(2047), ten...   \n",
       "57          1  [[tensor(101), tensor(2057), tensor(1010), ten...   \n",
       "132         3  [[tensor(101), tensor(2034), tensor(1010), ten...   \n",
       "\n",
       "                                       attention_masks  \n",
       "23   [tensor(1), tensor(1), tensor(1), tensor(1), t...  \n",
       "14   [tensor(1), tensor(1), tensor(1), tensor(1), t...  \n",
       "21   [tensor(1), tensor(1), tensor(1), tensor(1), t...  \n",
       "57   [tensor(1), tensor(1), tensor(1), tensor(1), t...  \n",
       "132  [tensor(1), tensor(1), tensor(1), tensor(1), t...  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['attention_masks'] = [i for i in df_train_attention_masks]\n",
    "df_val['attention_masks'] = [i for i in df_val_attention_masks]\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4464f9ec-e338-4066-9cc6-8a8819aba08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ad6ea397-c9b3-43e3-880d-b70bd843d16b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d002d7-f1fc-4a63-9600-03572d61badc",
   "metadata": {},
   "source": [
    "3. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a25af683-a011-4b86-950a-5d42cd11cbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the neural network model\n",
    "class DisasterSentimentModel(nn.Module):\n",
    "    def __init__(self, num_labels1, num_labels2, num_labels4, num_labels5, num_labels6, num_labels7):\n",
    "        super(DisasterSentimentModel, self).__init__()\n",
    "        self.bert_layer = BertModel.from_pretrained('bert-base-uncased')\n",
    "        for param in self.bert_layer.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.dropout_layer = nn.Dropout(0.3)\n",
    "        \n",
    "        self.dense_layer1 = nn.Linear(self.bert_layer.config.hidden_size, 512)\n",
    "        self.classifier_layer1 = nn.Linear(512, num_labels1)\n",
    "        \n",
    "        self.dense_layer2 = nn.Linear(self.bert_layer.config.hidden_size, 512)\n",
    "        self.classifier_layer2 = nn.Linear(512, num_labels2)\n",
    "\n",
    "        #self.dense_layer3 = nn.Linear(self.bert_layer.config.hidden_size, 512)\n",
    "        #self.classifier_layer3 = nn.Linear(512, num_labels3)\n",
    "        \n",
    "        self.dense_layer4 = nn.Linear(self.bert_layer.config.hidden_size, 512)\n",
    "        self.classifier_layer4 = nn.Linear(512, num_labels4)\n",
    "\n",
    "        self.dense_layer5 = nn.Linear(self.bert_layer.config.hidden_size, 512)\n",
    "        self.classifier_layer5 = nn.Linear(512, num_labels5)\n",
    "\n",
    "        self.dense_layer6 = nn.Linear(self.bert_layer.config.hidden_size, 512)\n",
    "        self.classifier_layer6 = nn.Linear(512, num_labels6)\n",
    "\n",
    "        self.dense_layer7 = nn.Linear(self.bert_layer.config.hidden_size, 512)\n",
    "        self.classifier_layer7 = nn.Linear(512, num_labels7)\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        bert_output = self.bert_layer(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = bert_output[0]\n",
    "        pooled_output = pooled_output[:, 0]\n",
    "        \n",
    "        output1 = self.dense_layer1(pooled_output)\n",
    "        output1 = nn.ReLU()(output1)\n",
    "        output1 = self.dropout_layer(output1)\n",
    "        output1 = torch.softmax(self.classifier_layer1(output1), dim=-1)\n",
    "        \n",
    "        output2 = self.dense_layer2(pooled_output)\n",
    "        output2 = nn.ReLU()(output2)\n",
    "        output2 = self.dropout_layer(output2)\n",
    "        output2 = torch.softmax(self.classifier_layer2(output2), dim=-1)\n",
    "\n",
    "        #output3 = self.dense_layer1(pooled_output)\n",
    "        #output3 = nn.ReLU()(output3)\n",
    "        #output3 = self.dropout_layer(output3)\n",
    "        #output3 = torch.softmax(self.classifier_layer1(output3), dim=-1)\n",
    "        \n",
    "        output4 = self.dense_layer2(pooled_output)\n",
    "        output4 = nn.ReLU()(output4)\n",
    "        output4 = self.dropout_layer(output4)\n",
    "        output4 = torch.softmax(self.classifier_layer2(output4), dim=-1)\n",
    "\n",
    "        output5 = self.dense_layer1(pooled_output)\n",
    "        output5 = nn.ReLU()(output5)\n",
    "        output5 = self.dropout_layer(output5)\n",
    "        output5 = torch.softmax(self.classifier_layer1(output5), dim=-1)\n",
    "        \n",
    "        output6 = self.dense_layer2(pooled_output)\n",
    "        output6 = nn.ReLU()(output6)\n",
    "        output6 = self.dropout_layer(output6)\n",
    "        output6 = torch.softmax(self.classifier_layer2(output6), dim=-1)\n",
    "\n",
    "        output7 = self.dense_layer2(pooled_output)\n",
    "        output7 = nn.ReLU()(output7)\n",
    "        output7 = self.dropout_layer(output7)\n",
    "        output7 = torch.softmax(self.classifier_layer2(output7), dim=-1)\n",
    "\n",
    "        #return output1, output2, output3, output4, output5, output6, output7\n",
    "        return output1, output2, output4, output5, output6, output7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1ca9b28e-f515-4939-af92-167b94d197ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loader for Multi-Task Learning\n",
    "batch_size = 16\n",
    "\n",
    "input_ids = torch.from_numpy(np.vstack(df_train['input_ids'].values))\n",
    "attention_masks = torch.from_numpy(np.vstack(df_train['attention_masks'].values))\n",
    "d1_label = torch.from_numpy(np.vstack(df_train['BACE_Blank'].values))\n",
    "d2_label = torch.from_numpy(np.vstack(df_train['DIS_Blank'].values))\n",
    "#d3_label = torch.from_numpy(np.vstack(df_train['IGB_Blank'].values))\n",
    "d4_label = torch.from_numpy(np.vstack(df_train['SC_Blank'].values))\n",
    "d5_label = torch.from_numpy(np.vstack(df_train['TASK_Blank'].values))\n",
    "d6_label = torch.from_numpy(np.vstack(df_train['PWR_Blank'].values))\n",
    "d7_label = torch.from_numpy(np.vstack(df_train['CC_Blank'].values))\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(input_ids,\n",
    "                                                attention_masks,\n",
    "                                                d1_label,\n",
    "                                                d2_label,\n",
    "                                                #d3_label,\n",
    "                                                d4_label,\n",
    "                                                d5_label,\n",
    "                                                d6_label,\n",
    "                                                d7_label)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe7d34e-6bb1-42e7-bce2-0b5c0b4cf4ad",
   "metadata": {},
   "source": [
    "4. We want to train M for both T1 and T2 on D12 by minimizing a weighted loss λ1 * l1 + λ2 * l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "742d21e9-bad6-4983-812a-e28e8e361940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mtl_train(model, dataloader, max_epochs, print_loss=False):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for batch_idx, batch in enumerate(dataloader):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            #input_ids, attention_masks, d1_label, d2_label, d3_label, d4_label, d5_label, d6_label, d7_label = batch\n",
    "            input_ids, attention_masks, d1_label, d2_label, d4_label, d5_label, d6_label, d7_label = batch\n",
    "\n",
    "            # 标签映射\n",
    "            d1_label, d2_label, d4_label, d5_label, d6_label, d7_label = [\n",
    "                label - 1 for label in [d1_label, d2_label, d4_label, d5_label, d6_label, d7_label]\n",
    "            ]\n",
    "            #d3_label = (d3_label - 1) // 3\n",
    "\n",
    "            # 前向传播\n",
    "            outputs = model(input_ids, attention_masks)\n",
    "\n",
    "            # 计算损失\n",
    "            losses = []\n",
    "            for output, label in zip(outputs, [d1_label, d2_label, d4_label, d5_label, d6_label, d7_label]):\n",
    "                label = label.squeeze().long()  # 确保目标为 1D 且是 LongTensor\n",
    "                losses.append(loss_fn(output, label))\n",
    "            \n",
    "            total_task_loss = sum(losses)\n",
    "\n",
    "            # 反向传播\n",
    "            optimizer.zero_grad()\n",
    "            total_task_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += total_task_loss.item()\n",
    "\n",
    "            if print_loss:\n",
    "                print(f\"Batch {batch_idx + 1}/{len(dataloader)}, Loss: {total_task_loss.item():.4f}\")\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{max_epochs}, Average Loss: {total_loss / len(dataloader):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "eb9b8d81-b8c3-40b2-a18c-e5a0e3ea0913",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "def mtl_evaluate(model, dataloader, return_labels=False):\n",
    "    model.eval()\n",
    "\n",
    "    # 初始化存储容器，每个任务单独存储预测值和真实标签\n",
    "    task_preds = {f\"d{i}_preds\": [] for i in range(1, 8)}\n",
    "    task_labels = {f\"d{i}_labels\": [] for i in range(1, 8)}\n",
    "\n",
    "    # 遍历验证数据集\n",
    "    for batch in tqdm(dataloader):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, attention_masks, d1_label, d2_label, d4_label, d5_label, d6_label, d7_label = batch\n",
    "\n",
    "        # 标签映射\n",
    "        d1_label, d2_label, d4_label, d5_label, d6_label, d7_label = [\n",
    "            label - 1 for label in [d1_label, d2_label, d4_label, d5_label, d6_label, d7_label]\n",
    "        ]\n",
    "        #d3_label = (d3_label - 1) // 3\n",
    "\n",
    "        # 前向传播\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids, attention_masks)\n",
    "\n",
    "        # 分别处理每个任务\n",
    "        labels = [d1_label, d2_label, d4_label, d5_label, d6_label, d7_label]\n",
    "        for i in range(6):\n",
    "            task_label = labels[i].flatten()\n",
    "            valid_mask = ~torch.isnan(task_label)  # 筛选有效标签\n",
    "            valid_indices = torch.arange(len(task_label)).to(device)[valid_mask]\n",
    "\n",
    "            if len(valid_indices) > 0:  # 若存在有效样本\n",
    "                task_output = outputs[i][valid_indices]\n",
    "                task_pred = torch.argmax(task_output, axis=1).detach().cpu().numpy().tolist()\n",
    "                # 存储预测值和真实标签\n",
    "                task_preds[f\"d{i+1}_preds\"] += task_pred\n",
    "                task_labels[f\"d{i+1}_labels\"] += task_label[valid_indices].cpu().numpy().tolist()\n",
    "\n",
    "    # 计算每个任务的 F1 和 Accuracy\n",
    "    results = {}\n",
    "    for i in range(6):\n",
    "        preds = task_preds[f\"d{i+1}_preds\"]\n",
    "        labels = task_labels[f\"d{i+1}_labels\"]\n",
    "        \n",
    "        if len(preds) > 0:\n",
    "            f1 = f1_score(labels, preds, average='weighted')\n",
    "            accuracy = accuracy_score(labels, preds)\n",
    "            results[f\"Task {i+1}\"] = {\"F1 Score\": f1, \"Accuracy\": accuracy}\n",
    "            print(f\"Task {i+1} - F1 Score: {f1:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "        else:\n",
    "            results[f\"Task {i+1}\"] = {\"F1 Score\": None, \"Accuracy\": None}\n",
    "            print(f\"Task {i+1} - No valid samples for evaluation.\")\n",
    "\n",
    "    # 根据需求返回标签和预测值\n",
    "    if return_labels:\n",
    "        return task_labels, task_preds\n",
    "    else:\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6669745b-c451-49d0-be48-9bd3c6657352",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dataway/anaconda3/envs/pytorch_env/lib/python3.8/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1/8, Loss: 8.3519\n",
      "Batch 2/8, Loss: 8.3201\n",
      "Batch 3/8, Loss: 8.3042\n",
      "Batch 4/8, Loss: 8.2552\n",
      "Batch 5/8, Loss: 8.2509\n",
      "Batch 6/8, Loss: 8.2192\n",
      "Batch 7/8, Loss: 8.1710\n",
      "Batch 8/8, Loss: 8.1510\n",
      "Epoch 1/10, Average Loss: 8.2529\n",
      "Batch 1/8, Loss: 8.1326\n",
      "Batch 2/8, Loss: 8.0668\n",
      "Batch 3/8, Loss: 8.1360\n",
      "Batch 4/8, Loss: 8.0968\n",
      "Batch 5/8, Loss: 8.0006\n",
      "Batch 6/8, Loss: 8.0366\n",
      "Batch 7/8, Loss: 7.8501\n",
      "Batch 8/8, Loss: 8.0341\n",
      "Epoch 2/10, Average Loss: 8.0442\n",
      "Batch 1/8, Loss: 7.7954\n",
      "Batch 2/8, Loss: 7.9753\n",
      "Batch 3/8, Loss: 8.0188\n",
      "Batch 4/8, Loss: 8.0438\n",
      "Batch 5/8, Loss: 7.7973\n",
      "Batch 6/8, Loss: 7.9398\n",
      "Batch 7/8, Loss: 7.9486\n",
      "Batch 8/8, Loss: 8.0289\n",
      "Epoch 3/10, Average Loss: 7.9435\n",
      "Batch 1/8, Loss: 7.7845\n",
      "Batch 2/8, Loss: 7.8501\n",
      "Batch 3/8, Loss: 7.9170\n",
      "Batch 4/8, Loss: 8.0477\n",
      "Batch 5/8, Loss: 7.7496\n",
      "Batch 6/8, Loss: 7.9188\n",
      "Batch 7/8, Loss: 8.0713\n",
      "Batch 8/8, Loss: 7.8701\n",
      "Epoch 4/10, Average Loss: 7.9011\n",
      "Batch 1/8, Loss: 7.9100\n",
      "Batch 2/8, Loss: 7.6671\n",
      "Batch 3/8, Loss: 7.5833\n",
      "Batch 4/8, Loss: 8.0146\n",
      "Batch 5/8, Loss: 8.1163\n",
      "Batch 6/8, Loss: 7.8590\n",
      "Batch 7/8, Loss: 7.8083\n",
      "Batch 8/8, Loss: 8.0509\n",
      "Epoch 5/10, Average Loss: 7.8762\n",
      "Batch 1/8, Loss: 7.8381\n",
      "Batch 2/8, Loss: 8.0438\n",
      "Batch 3/8, Loss: 8.1327\n",
      "Batch 4/8, Loss: 7.6786\n",
      "Batch 5/8, Loss: 7.8693\n",
      "Batch 6/8, Loss: 7.9462\n",
      "Batch 7/8, Loss: 7.6404\n",
      "Batch 8/8, Loss: 7.7170\n",
      "Epoch 6/10, Average Loss: 7.8583\n",
      "Batch 1/8, Loss: 7.9286\n",
      "Batch 2/8, Loss: 7.8622\n",
      "Batch 3/8, Loss: 7.7177\n",
      "Batch 4/8, Loss: 7.9780\n",
      "Batch 5/8, Loss: 7.8669\n",
      "Batch 6/8, Loss: 7.9834\n",
      "Batch 7/8, Loss: 7.6432\n",
      "Batch 8/8, Loss: 7.8093\n",
      "Epoch 7/10, Average Loss: 7.8487\n",
      "Batch 1/8, Loss: 7.9634\n",
      "Batch 2/8, Loss: 7.8824\n",
      "Batch 3/8, Loss: 7.9869\n",
      "Batch 4/8, Loss: 7.9131\n",
      "Batch 5/8, Loss: 7.8496\n",
      "Batch 6/8, Loss: 7.7821\n",
      "Batch 7/8, Loss: 7.7985\n",
      "Batch 8/8, Loss: 7.4726\n",
      "Epoch 8/10, Average Loss: 7.8311\n",
      "Batch 1/8, Loss: 8.0056\n",
      "Batch 2/8, Loss: 8.0463\n",
      "Batch 3/8, Loss: 7.7087\n",
      "Batch 4/8, Loss: 7.7389\n",
      "Batch 5/8, Loss: 7.8069\n",
      "Batch 6/8, Loss: 7.7170\n",
      "Batch 7/8, Loss: 7.7830\n",
      "Batch 8/8, Loss: 7.7849\n",
      "Epoch 9/10, Average Loss: 7.8239\n",
      "Batch 1/8, Loss: 7.9156\n",
      "Batch 2/8, Loss: 7.9015\n",
      "Batch 3/8, Loss: 7.8264\n",
      "Batch 4/8, Loss: 7.7558\n",
      "Batch 5/8, Loss: 7.8375\n",
      "Batch 6/8, Loss: 7.7461\n",
      "Batch 7/8, Loss: 7.7922\n",
      "Batch 8/8, Loss: 7.5731\n",
      "Epoch 10/10, Average Loss: 7.7935\n"
     ]
    }
   ],
   "source": [
    "# define new model to train on both d1 and d2 labels\n",
    "md = DisasterSentimentModel(num_labels1=4, num_labels2=4, num_labels4=4, num_labels5=4, num_labels6=4, num_labels7=4).to(device)\n",
    "mtl_train(md, train_loader, 10, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f01b2de1-d282-412d-a842-8087ba148aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loader for Multi-Task Learning\n",
    "batch_size = 16\n",
    "\n",
    "input_ids = torch.from_numpy(np.vstack(df_val['input_ids'].values))\n",
    "attention_masks = torch.from_numpy(np.vstack(df_val['attention_masks'].values))\n",
    "d1_label = torch.from_numpy(np.vstack(df_val['BACE_Blank'].values))\n",
    "d2_label = torch.from_numpy(np.vstack(df_val['DIS_Blank'].values))\n",
    "#d3_label = torch.from_numpy(np.vstack(df_val['IGB_Blank'].values))\n",
    "d4_label = torch.from_numpy(np.vstack(df_val['SC_Blank'].values))\n",
    "d5_label = torch.from_numpy(np.vstack(df_val['TASK_Blank'].values))\n",
    "d6_label = torch.from_numpy(np.vstack(df_val['PWR_Blank'].values))\n",
    "d7_label = torch.from_numpy(np.vstack(df_val['CC_Blank'].values))\n",
    "\n",
    "val_data = torch.utils.data.TensorDataset(input_ids,\n",
    "                                                attention_masks,\n",
    "                                                d1_label,\n",
    "                                                d2_label,\n",
    "                                                #d3_label,\n",
    "                                                d4_label,\n",
    "                                                d5_label,\n",
    "                                                d6_label,\n",
    "                                                d7_label)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7099f2c4-42c3-4840-a720-275006aa7e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 34.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1 - F1 Score: 0.3717, Accuracy: 0.4062\n",
      "Task 2 - F1 Score: 0.5200, Accuracy: 0.6562\n",
      "Task 3 - F1 Score: 0.3333, Accuracy: 0.5000\n",
      "Task 4 - F1 Score: 0.1792, Accuracy: 0.2500\n",
      "Task 5 - F1 Score: 0.2347, Accuracy: 0.4062\n",
      "Task 6 - F1 Score: 0.1000, Accuracy: 0.2500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy and print the result\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "labels, preds = mtl_evaluate(md, val_loader, return_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf841000-0773-4e45-b0e6-983ecf8f2d94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
